import os
import logging
import tempfile
from dotenv import load_dotenv
from fastapi import APIRouter, HTTPException, Depends, Path, BackgroundTasks
from fastapi.responses import StreamingResponse, FileResponse
from fastapi.templating import Jinja2Templates
from openai import AsyncOpenAI
import boto3
from exceptions.http_exceptions import OpenAIError
from utils.chat.files import FILE_PATHS, cleanup_temp_file

logger = logging.getLogger("uvicorn.error")

# Jinja2 templates
templates = Jinja2Templates(directory="templates")

# Check if environment variables are missing
load_dotenv(override=True)
assistant_id_env_var: str | None = os.getenv("ASSISTANT_ID")

if not assistant_id_env_var:
    raise OpenAIError("OpenAI API key or assistant ID is missing")
else:
    assistant_id: str = assistant_id_env_var

router = APIRouter(
    prefix="/chat/files",
    tags=["chat_files"]
)


# TODO: FILE_PATHS no longer points to s3 urls; we will need to get these from Document.storage_url instead
@router.get("/{file_name}")
async def download_assistant_file(
    background_tasks: BackgroundTasks,
    file_name: str = Path(..., description="The name of the file to retrieve")
) -> FileResponse:
    """Serves an assistant file stored locally in the uploads directory."""
        # Initialize the S3 client
    s3 = boto3.client(
        's3',
        aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID", ""),
        aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY", ""),
        region_name=os.getenv("AWS_REGION", "us-east-1")
    )

    bucket_name = os.getenv("S3_BUCKET", "")
    s3_file_path = FILE_PATHS.get(file_name)

    if not s3_file_path:
        raise HTTPException(
            status_code=404,
            detail=f"File configuration not found for: {file_name}"
        )

    # Create a temporary file that persists until manually deleted
    temp_file = tempfile.NamedTemporaryFile(delete=False)
    temp_file_path = temp_file.name

    try:
        # Close the file handle immediately after creation, we only need the path
        temp_file.close()

        # Download the file directly to the temp file path
        logger.info(f"Downloading s3://{bucket_name}/{s3_file_path} to {temp_file_path}")
        s3.download_file(bucket_name, s3_file_path, temp_file_path)

        # Schedule the cleanup task to run after the response is completely sent
        background_tasks.add_task(cleanup_temp_file, temp_file_path)

        # Return the file response
        return FileResponse(
            path=temp_file_path,
            filename=file_name
        )
    except Exception as e:
        # Ensure cleanup happens even if download or response creation fails
        cleanup_temp_file(temp_file_path)
        logger.error(f"Error downloading file s3://{bucket_name}/{s3_file_path}: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to download file: {e}"
        )


@router.get("/{file_id}/content")
async def get_file_content(
    file_id: str,
    client: AsyncOpenAI = Depends(lambda: AsyncOpenAI())
) -> StreamingResponse:
    """
    Streams file content from OpenAI API.
    This route is used to serve images and other files generated by the code interpreter.
    """
    try:
        # Get the file content from OpenAI
        file_content = await client.files.content(file_id)
        file_bytes = file_content.read()  # Remove await since read() returns bytes directly
        
        # Return the file content as a streaming response
        # Note: In a production environment, you might want to add caching
        return StreamingResponse(
            content=iter([file_bytes]),
            media_type="image/png"  # You might want to make this dynamic based on file type
        )
    except Exception as e:
        logger.error(f"Error getting file content: {e}")
        raise HTTPException(status_code=500, detail=str(e))
